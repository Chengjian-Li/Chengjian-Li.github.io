---
title:          "Plenodium: UnderWater 3D Scene Reconstruction with Plenoptic Medium Representation"
date:           2025-09-18 00:01:00 +0800
selected:       true
pub:            "NeurIPS"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"

# abstract: >-
#  As the two most typical classic network models, convolutional neural networks (CNNs) and Transformer have been widely applied in obstructive sleep apnea (OSA) detection in recent years. However, due to the inherent limitations of the receptive field in traditional CNN models (the receptive field is positively correlated with the fixed convolutional kernel size, and the ability to extract global feature information is limited), further improvement in their performance is constrained. While, for the Transformer, due to the computational complexity of the self-attention mechanism in the Transformer model increases exponentially with the length of the context, it will hold a very high computational overhead, and which would hinder the deployment of the Transformer on devices with limited computing resources. To address these problems, this article proposes an adaptive bidirectional selective state-space model (ABSM)-based method for OSA detection, termed as OSAMamba. The main novelty of the proposed method lies in the following two aspects: the development of the lightweight multiscale efficient aggregation (LMSEA) module and the propose of ABSM. To achieve the purpose of expanding the model receptive field and capturing the effective temporal features with a very low number of parameters, the LMSEA module adopts a combination of partial convolution (PConv)-based multiscale strategy and convolutional block attention module (CBAM). The purpose of the ABSM module is to reduce the computational cost of the model and improve the model deployability by using a frequency-domain enhancement strategy to fuse the effective time-domain features extracted by adaptive bidirectional Mamba (ABi-Mamba) with linear complexity with the frequency-domain features extracted by the frequency-domain enhancement module (FEM). Extensive experiments on the Apnea-electrocardiogram (ECG) dataset show that of all compared methods, the proposed method obtains the best accuracy of 91.91% in the per-segment detection, and which surpasses the state-of-the-art (SOTA) TFFormer by 0.31%. It also achieves a remarkable accuracy of 100% with the lowest mean absolute error (MAE) of 2.43 in per-record detection.
cover:          assets\images\covers\OSAMamba.jpg
authors:
  - Changguanng Wu 
  - Jiangxin Dong
  - Chengjian Li
  - Jinhui Tang

links:
    Paper: https://arxiv.org/abs/2505.21258
#   Code: https://github.com/luost26/bubble-visual-hash
#   Demo: https://luost26.github.io/bubble-visual-hash
---
