---
title:          "Transformer 驱动的图像分类研究进展"
date:           2023-09-1 00:01:00 +0800
selected:       true
pub:            "中国图象图形学报 "
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2023"

# abstract: >-
#   图像分类是图像理解的基础，对计算机视觉在实际中的应用具有重要作用。然而由于图像目标形态、类型的多样性以及成像环境的复杂性，导致很多图像分类方法在实际应用中的分类结果总是差强人意，例如依然存在分类准确性低、假阳性高等问题，严重影响其在后续图像及计算机视觉相关任务中的应用。因此，如何通过后期算法提高图像分类的精度和准确性具有重要研究意义，受到越来越多的关注。随着深度学习技术的快速发展及其在图像处理中的广泛应用和优异表现，基于深度学习技术的图像分类方法研究取得了巨大进展。为了更加全面地对现有方法进行研究，紧跟最新研究进展，本文对Transformer驱动的深度学习图像分类方法和模型进行系统梳理和总结。与已有主题相似综述不同，本文重点对Transformer变体驱动的深度学习图像分类方法和模型进行归纳和总结，包括基于可扩展位置编码的Transformer图像分类方法、具有低复杂度和低计算代价的Transformer图像分类方法、局部信息与全局信息融合的Transformer图像分类方法以及基于深层ViT（visual Transformer）模型的图像分类方法等，从设计思路、结构特点和存在问题等多个维度、多个层面深度分析总结现有方法。为了更好地对不同方法进行比较分析，在ImageNet、CIFAR-10（Canadian Institute for Advanced Research）和CIFAR-100等公开图像分类数据集上，采用准确率、参数量、浮点运算数（floating point operations，FLOPs）、总体分类精度（overall accuracy，OA）、平均分类精度（average accuracy，AA）和Kappa（κ）系数等评价指标，对不同方法模型的分类性能进行了实验评估。最后，对未来研究方向进行了展望。
# cover:         assets\images\covers\Transformer.jpg
authors:
  - Zhenghao Shi
  - Chengjian Li 
  - Liang Zhou
  - Zhijun Zhang
  - Chenwei Wu
  - Zhenzhen You
  - Wenqi Ren

links:
    Paper: https://www.cjig.cn/zh/article/doi/10.11834/jig.220799/
#   Code: https://github.com/luost26/bubble-visual-hash
#   Demo: https://luost26.github.io/bubble-visual-hash
---
